"""Interview handlers."""
import os
import logging
import tempfile
from aiogram import Router, F
from aiogram.filters import Command
from aiogram.types import Message, ReplyKeyboardRemove
from aiogram.fsm.context import FSMContext

from bot.instance import bot
from bot.keyboards import get_main_menu_keyboard, get_interview_keyboard
from bot.states import InterviewStates
from bot.handlers.utils import extract_topics_from_messages
from config import config
from services.api import backend_api
from services.ai import ai_service
from services.storage import user_storage

logger = logging.getLogger(__name__)
router = Router()


@router.message(Command("interview"))
@router.message(F.text == "üìñ –ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é")
async def start_interview(message: Message, state: FSMContext):
    """Start or continue the interview process."""
    data = await state.get_data()

    if not data.get("relative_id"):
        # Try to restore from storage
        user_data = user_storage.get_user(message.from_user.id)
        if user_data:
            await state.update_data(
                relative_id=user_data["relative_id"],
                relative_name=user_data.get("name", ""),
                interview_messages=[],
                total_messages_count=0,
            )
            data = await state.get_data()
        else:
            await message.answer(
                "–°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–π–¥–∏—Ç–µ –∞–∫—Ç–∏–≤–∞—Ü–∏—é –ø–æ —Å—Å—ã–ª–∫–µ-–ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏—é –æ—Ç —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞.",
                reply_markup=ReplyKeyboardRemove(),
            )
            return

    relative_name = data.get("relative_name", "")
    messages = data.get("interview_messages", [])

    # Send thinking indicator
    thinking_msg = await message.answer("...")

    # Get first/next question from AI
    covered_topics = extract_topics_from_messages(messages) if messages else []
    first_question, success = await ai_service.get_interview_question(
        messages, relative_name, covered_topics
    )

    # Delete thinking message
    await thinking_msg.delete()

    if not success:
        await message.answer(
            "‚ö†Ô∏è AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=get_main_menu_keyboard(),
        )
        return

    # Update state
    if not messages:
        messages = [{"role": "assistant", "content": first_question}]
        intro = f"–ü—Ä–∏–≤–µ—Ç! –î–∞–≤–∞–π –Ω–∞—á–Ω—ë–º.\n\n{first_question}\n\n_–ú–æ–∂–Ω–æ —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤—ã–º_"
    else:
        messages.append({"role": "assistant", "content": first_question})
        intro = f"–ü—Ä–æ–¥–æ–ª–∂–∏–º.\n\n{first_question}"

    await state.update_data(interview_messages=messages)
    await state.set_state(InterviewStates.waiting_answer)

    # Update interaction time
    user_storage.update_user_interaction(message.from_user.id)

    await message.answer(
        intro,
        reply_markup=get_interview_keyboard(),
        parse_mode="Markdown",
    )


@router.message(InterviewStates.waiting_answer, F.voice)
async def handle_voice(message: Message, state: FSMContext):
    """Handle voice messages during interview."""
    import asyncio

    data = await state.get_data()

    if not data.get("relative_id"):
        await message.answer("–°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–π–¥–∏—Ç–µ –∞–∫—Ç–∏–≤–∞—Ü–∏—é –ø–æ —Å—Å—ã–ª–∫–µ-–ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏—é.")
        return

    # Check voice duration - warn if too long
    voice_duration = message.voice.duration if message.voice else 0
    if voice_duration > 180:  # 3 minutes
        await message.answer(
            "‚ö†Ô∏è –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–µ. "
            "–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è..."
        )

    # Show transcription indicator
    transcribe_msg = await message.answer("üéß –†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")

    file_path = None
    try:
        # Download voice file with timeout
        try:
            file = await asyncio.wait_for(
                bot.get_file(message.voice.file_id),
                timeout=30
            )
        except asyncio.TimeoutError:
            logger.error("Timeout getting voice file info")
            await transcribe_msg.edit_text(
                "‚è±Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å –∫–æ—Ä–æ—á–µ –∏–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º."
            )
            return

        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as tmp_file:
            file_path = tmp_file.name

        try:
            await asyncio.wait_for(
                bot.download_file(file.file_path, destination=file_path),
                timeout=60
            )
        except asyncio.TimeoutError:
            logger.error("Timeout downloading voice file")
            await transcribe_msg.edit_text(
                "‚è±Ô∏è –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –∑–∞–Ω—è–ª–∞ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å –∫–æ—Ä–æ—á–µ –∏–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º."
            )
            return

        # Transcribe with timeout
        try:
            text = await asyncio.wait_for(
                ai_service.transcribe_voice(file_path),
                timeout=120  # 2 minutes for transcription
            )
        except asyncio.TimeoutError:
            logger.error("Timeout transcribing voice")
            await transcribe_msg.edit_text(
                "‚è±Ô∏è –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –∑–∞–Ω—è–ª–∞ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–æ—Ä–æ—á–µ –∏–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º."
            )
            return

        await transcribe_msg.delete()

        if text:
            # Escape markdown special characters in transcription
            escaped_text = text.replace("_", "\\_").replace("*", "\\*").replace("`", "\\`")
            await message.answer(f"üìù *–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞:*\n_{escaped_text}_", parse_mode="Markdown")
            await process_interview_answer(message, state, text)
        else:
            await message.answer(
                "üîá –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏.\n\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
                "‚Ä¢ –ó–∞–ø–∏—Å–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ç–∏—Ö–æ–º –º–µ—Å—Ç–µ\n"
                "‚Ä¢ –ì–æ–≤–æ—Ä–∏—Ç—å —á—ë—Ç—á–µ –∏ –≥—Ä–æ–º—á–µ\n"
                "‚Ä¢ –ò–ª–∏ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º"
            )

    except Exception as e:
        logger.error(f"Error handling voice message: {e}", exc_info=True)
        try:
            await transcribe_msg.delete()
        except:
            pass
        await message.answer(
            "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º."
        )
    finally:
        # Clean up temp file
        if file_path:
            try:
                os.remove(file_path)
            except:
                pass


@router.message(InterviewStates.waiting_answer, F.text)
async def handle_text(message: Message, state: FSMContext):
    """Handle text messages during interview."""
    # Ignore menu buttons
    if message.text in ["‚è∏ –ü–∞—É–∑–∞", "üõë –ó–∞–≤–µ—Ä—à–∏—Ç—å", "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏"]:
        return

    data = await state.get_data()

    if not data.get("relative_id"):
        await message.answer("–°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–π–¥–∏—Ç–µ –∞–∫—Ç–∏–≤–∞—Ü–∏—é –ø–æ —Å—Å—ã–ª–∫–µ-–ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏—é.")
        return

    await process_interview_answer(message, state, message.text)


async def process_interview_answer(message: Message, state: FSMContext, answer_text: str):
    """Process interview answer and get next question."""
    data = await state.get_data()
    messages = data.get("interview_messages", [])
    relative_id = data["relative_id"]
    relative_name = data.get("relative_name", "")
    total_count = data.get("total_messages_count", 0)
    stories_in_session = data.get("stories_in_session", 0)

    # Add user answer to conversation
    messages.append({"role": "user", "content": answer_text})
    total_count += 1

    # Check if we should create a story
    user_message_count = sum(1 for m in messages if m["role"] == "user")

    if (
        user_message_count > 0
        and user_message_count % config.MESSAGES_BEFORE_STORY == 0
    ):
        # Create story from recent messages (4 Q&A pairs = 8 messages + initial question)
        # Formula: MESSAGES_BEFORE_STORY * 2 gets all Q&A pairs
        messages_to_take = config.MESSAGES_BEFORE_STORY * 2 + 1
        recent_messages = messages[-messages_to_take:]

        await message.answer("‚ú® –°–æ—Ö—Ä–∞–Ω—è—é –∏—Å—Ç–æ—Ä–∏—é...")

        story_result = await ai_service.create_story(recent_messages)
        if story_result:
            title, story_text = story_result
            success = await backend_api.save_story(relative_id, title, story_text)
            if success:
                stories_in_session += 1
                # Show more of the story (up to 1500 chars) or full if shorter
                preview_length = min(len(story_text), 1500)
                story_preview = story_text[:preview_length]
                if len(story_text) > preview_length:
                    story_preview += "..."

                # Escape markdown special characters
                story_preview = story_preview.replace("_", "\\_").replace("*", "\\*")

                await message.answer(
                    f"üìñ *{title}*\n\n"
                    f"{story_preview}",
                    parse_mode="Markdown",
                )
                # Trim if too long to avoid token limits
                if len(messages) > config.MAX_CONVERSATION_LENGTH:
                    messages = messages[-18:]  # Keep more context for 4 questions

    # Show thinking indicator
    thinking_msg = await message.answer("...")

    # Extract covered topics to avoid repetition
    covered_topics = extract_topics_from_messages(messages)

    # Get AI response with topic awareness
    ai_question, success = await ai_service.get_interview_question(
        messages, relative_name, covered_topics
    )

    # Delete thinking message
    await thinking_msg.delete()

    if not success:
        await message.answer(
            "‚ö†Ô∏è AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.\n\n"
            "–í–∞—à –æ—Ç–≤–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–æ–∑–∂–µ.",
            reply_markup=get_main_menu_keyboard(),
        )
        await state.set_state(None)
        return

    messages.append({"role": "assistant", "content": ai_question})

    # Update state
    await state.update_data(
        interview_messages=messages,
        total_messages_count=total_count,
        stories_in_session=stories_in_session,
    )

    # Update interaction time
    user_storage.update_user_interaction(message.from_user.id)

    # Send next question
    await message.answer(ai_question, reply_markup=get_interview_keyboard())

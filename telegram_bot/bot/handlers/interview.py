"""Interview handlers."""
import json
import os
import logging
import tempfile
from aiogram import Router, F
from aiogram.filters import Command
from aiogram.types import Message, ReplyKeyboardRemove, CallbackQuery
from aiogram.fsm.context import FSMContext

from bot.instance import bot
from bot.keyboards import (
    get_main_menu_keyboard,
    get_interview_keyboard,
    get_story_confirmation_keyboard,
    get_relationship_keyboard,
    get_relative_confirmation_keyboard,
    get_photo_collection_keyboard,
)
from bot.states import InterviewStates
from bot.handlers.utils import extract_topics_from_messages
from config import config
from services.api import backend_api
from services.ai import ai_service
from services.storage import user_storage

logger = logging.getLogger(__name__)
router = Router()

# Relationship type translations for display
RELATIONSHIP_TRANSLATIONS = {
    "mother": "–ú–∞—Ç—å",
    "father": "–û—Ç–µ—Ü",
    "brother": "–ë—Ä–∞—Ç",
    "sister": "–°–µ—Å—Ç—Ä–∞",
    "grandfather": "–î–µ–¥—É—à–∫–∞",
    "grandmother": "–ë–∞–±—É—à–∫–∞",
    "uncle": "–î—è–¥—è",
    "aunt": "–¢—ë—Ç—è",
    "son": "–°—ã–Ω",
    "daughter": "–î–æ—á—å",
    "spouse": "–°—É–ø—Ä—É–≥(–∞)",
}

# Minimum questions before story can be created
MIN_QUESTIONS_FOR_STORY = 3


def get_progress_text(question_num: int) -> str:
    """Get progress indicator text."""
    if question_num < MIN_QUESTIONS_FOR_STORY:
        remaining = MIN_QUESTIONS_FOR_STORY - question_num
        return f"[–í–æ–ø—Ä–æ—Å {question_num} | –ï—â—ë {remaining} –¥–æ —Å–æ–∑–¥–∞–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏]"
    else:
        return f"[–í–æ–ø—Ä–æ—Å {question_num} | –ú–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é]"


@router.message(Command("interview"))
@router.message(F.text == "üìñ –ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é")
async def start_interview(message: Message, state: FSMContext):
    """Start or continue the interview process."""
    data = await state.get_data()

    if not data.get("relative_id"):
        # Try to restore from storage
        user_data = user_storage.get_user(message.from_user.id)
        if user_data:
            await state.update_data(
                relative_id=user_data["relative_id"],
                relative_name=user_data.get("name", ""),
                interview_messages=[],
                question_count=0,
            )
            data = await state.get_data()
        else:
            await message.answer(
                "–°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–π–¥–∏—Ç–µ –∞–∫—Ç–∏–≤–∞—Ü–∏—é –ø–æ —Å—Å—ã–ª–∫–µ-–ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏—é –æ—Ç —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫–∞.",
                reply_markup=ReplyKeyboardRemove(),
            )
            return

    relative_id = data.get("relative_id")
    relative_name = data.get("relative_name", "")
    messages = data.get("interview_messages", [])
    question_count = data.get("question_count", 0)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ broadcast –≤–æ–ø—Ä–æ—Å–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–æ–≤–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤—å—é)
    first_question = None
    success = True
    if not messages:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–∞—á–∞–ª–æ –Ω–æ–≤–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤—å—é
        saved_broadcast_question = user_storage.get_and_clear_broadcast_question(message.from_user.id)
        if saved_broadcast_question:
            first_question = saved_broadcast_question
            logger.info(f"Using saved broadcast question for user {message.from_user.id}")

    # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ AI
    if not first_question:
        # Send thinking indicator
        thinking_msg = await message.answer("–ü–æ–¥–±–∏—Ä–∞—é –≤–æ–ø—Ä–æ—Å...")

        # Get related stories context for AI enrichment
        related_stories_context = await backend_api.get_related_stories(relative_id)

        # Get first/next question from AI
        covered_topics = extract_topics_from_messages(messages) if messages else []
        first_question, success = await ai_service.get_interview_question(
            messages, relative_name, covered_topics, related_stories_context
        )

        # Delete thinking message
        await thinking_msg.delete()

    if not success:
        await message.answer(
            "AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=get_main_menu_keyboard(),
        )
        return

    # Update question count
    question_count += 1

    # Update state
    if not messages:
        messages = [{"role": "assistant", "content": first_question}]
    else:
        messages.append({"role": "assistant", "content": first_question})

    await state.update_data(
        interview_messages=messages,
        question_count=question_count,
    )
    await state.set_state(InterviewStates.waiting_answer)

    # Update interaction time
    user_storage.update_user_interaction(message.from_user.id)

    # Build response with progress
    progress = get_progress_text(question_count)

    if question_count == 1:
        response_text = f"–î–∞–≤–∞–π –Ω–∞—á–Ω—ë–º!\n\n{first_question}\n\n{progress}\n\n_–ú–æ–∂–Ω–æ —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤—ã–º_"
    else:
        response_text = f"{first_question}\n\n{progress}"

    await message.answer(
        response_text,
        reply_markup=get_interview_keyboard(question_count, MIN_QUESTIONS_FOR_STORY),
        parse_mode="Markdown",
    )


@router.message(InterviewStates.waiting_answer, F.text == "‚ú® –°–æ–∑–¥–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é")
async def create_story_manually(message: Message, state: FSMContext):
    """User requested to create story from current interview."""
    data = await state.get_data()
    question_count = data.get("question_count", 0)

    if question_count < MIN_QUESTIONS_FOR_STORY:
        await message.answer(
            f"–ù—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –º–∏–Ω–∏–º—É–º –Ω–∞ {MIN_QUESTIONS_FOR_STORY} –≤–æ–ø—Ä–æ—Å–∞.\n"
            f"–°–µ–π—á–∞—Å: {question_count}",
            reply_markup=get_interview_keyboard(question_count, MIN_QUESTIONS_FOR_STORY),
        )
        return

    await create_story_from_messages(message, state)


@router.message(InterviewStates.waiting_answer, F.voice)
async def handle_voice(message: Message, state: FSMContext):
    """Handle voice messages during interview."""
    import asyncio

    data = await state.get_data()

    if not data.get("relative_id"):
        await message.answer("–°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–π–¥–∏—Ç–µ –∞–∫—Ç–∏–≤–∞—Ü–∏—é –ø–æ —Å—Å—ã–ª–∫–µ-–ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏—é.")
        return

    # Check voice duration - warn if too long
    voice_duration = message.voice.duration if message.voice else 0
    if voice_duration > 180:  # 3 minutes
        await message.answer(
            "–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–µ. "
            "–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è..."
        )

    # Show transcription indicator
    transcribe_msg = await message.answer("–†–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞—é...")

    file_path = None
    try:
        # Download voice file with timeout
        try:
            file = await asyncio.wait_for(
                bot.get_file(message.voice.file_id),
                timeout=30
            )
        except asyncio.TimeoutError:
            logger.error("Timeout getting voice file info")
            await transcribe_msg.edit_text(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å –∫–æ—Ä–æ—á–µ –∏–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º."
            )
            return

        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as tmp_file:
            file_path = tmp_file.name

        try:
            await asyncio.wait_for(
                bot.download_file(file.file_path, destination=file_path),
                timeout=60
            )
        except asyncio.TimeoutError:
            logger.error("Timeout downloading voice file")
            await transcribe_msg.edit_text(
                "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –∑–∞–Ω—è–ª–∞ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å –∫–æ—Ä–æ—á–µ –∏–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º."
            )
            return

        # Transcribe with timeout
        try:
            text = await asyncio.wait_for(
                ai_service.transcribe_voice(file_path),
                timeout=120  # 2 minutes for transcription
            )
        except asyncio.TimeoutError:
            logger.error("Timeout transcribing voice")
            await transcribe_msg.edit_text(
                "–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ –∑–∞–Ω—è–ª–∞ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–æ—Ä–æ—á–µ –∏–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º."
            )
            return

        await transcribe_msg.delete()

        if text:
            # Escape markdown special characters in transcription
            escaped_text = text.replace("_", "\\_").replace("*", "\\*").replace("`", "\\`")
            await message.answer(f"*–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞:*\n_{escaped_text}_", parse_mode="Markdown")
            await process_interview_answer(message, state, text)
        else:
            await message.answer(
                "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.\n\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
                "- –ó–∞–ø–∏—Å–∞—Ç—å –≤ —Ç–∏—Ö–æ–º –º–µ—Å—Ç–µ\n"
                "- –ì–æ–≤–æ—Ä–∏—Ç—å —á—ë—Ç—á–µ\n"
                "- –ò–ª–∏ –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º"
            )

    except Exception as e:
        logger.error(f"Error handling voice message: {e}", exc_info=True)
        try:
            await transcribe_msg.delete()
        except:
            pass
        await message.answer(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º."
        )
    finally:
        # Clean up temp file
        if file_path:
            try:
                os.remove(file_path)
            except:
                pass


@router.message(InterviewStates.waiting_answer, F.text)
async def handle_text(message: Message, state: FSMContext):
    """Handle text messages during interview."""
    # Ignore menu buttons
    if message.text in ["‚è∏ –ü–∞—É–∑–∞", "üõë –ó–∞–≤–µ—Ä—à–∏—Ç—å", "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏", "‚ú® –°–æ–∑–¥–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é"]:
        return

    data = await state.get_data()

    if not data.get("relative_id"):
        await message.answer("–°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–π–¥–∏—Ç–µ –∞–∫—Ç–∏–≤–∞—Ü–∏—é –ø–æ —Å—Å—ã–ª–∫–µ-–ø—Ä–∏–≥–ª–∞—à–µ–Ω–∏—é.")
        return

    await process_interview_answer(message, state, message.text)


async def process_interview_answer(message: Message, state: FSMContext, answer_text: str):
    """Process interview answer and get next question."""
    data = await state.get_data()
    messages = data.get("interview_messages", [])
    relative_id = data["relative_id"]
    relative_name = data.get("relative_name", "")
    question_count = data.get("question_count", 0)
    known_relatives = data.get("known_relatives", [])

    # Add user answer to conversation
    messages.append({"role": "user", "content": answer_text})

    # Update state with new message immediately
    await state.update_data(interview_messages=messages)

    # Show thinking indicator
    thinking_msg = await message.answer("...")

    # Check for mentioned relatives in the answer
    mentioned = await ai_service.analyze_for_mentioned_relatives(
        answer_text, existing_relatives=known_relatives
    )

    if mentioned and mentioned.get("found") and mentioned.get("name"):
        # Found a new relative mention - switch to collecting info
        await thinking_msg.delete()

        await state.update_data(
            mentioned_relative=mentioned,
            relative_info_collected={},
            relative_questions_asked=0,
            saved_answer_text=answer_text,  # Save for later continuation
        )
        await state.set_state(InterviewStates.collecting_relative_info)

        # Get first question about the relative
        question = await ai_service.get_relative_info_question(
            mentioned_name=mentioned["name"],
            probable_role=mentioned.get("probable_role", "other"),
            context=mentioned.get("context", ""),
            already_collected={},
            question_number=0,
        )

        name = mentioned["name"]
        role = mentioned.get("probable_role", "—Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫")
        role_ru = RELATIONSHIP_TRANSLATIONS.get(role, "—Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫")

        await message.answer(
            f"–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ! –¢—ã —É–ø–æ–º—è–Ω—É–ª(–∞) {name} ({role_ru}).\n\n"
            f"–•–æ—á—É —É–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ. {question}\n\n"
            f"_–ú–æ–∂–µ—à—å –Ω–∞–ø–∏—Å–∞—Ç—å \"–ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å\" —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ –∏–Ω—Ç–µ—Ä–≤—å—é_",
            parse_mode="Markdown",
        )
        return

    # Regular flow - continue with interview
    # Extract covered topics to avoid repetition
    covered_topics = extract_topics_from_messages(messages)

    # Get related stories context for AI enrichment
    related_stories_context = await backend_api.get_related_stories(relative_id)

    # Get AI response with topic awareness and family context
    ai_question, success = await ai_service.get_interview_question(
        messages, relative_name, covered_topics, related_stories_context
    )

    # Delete thinking message
    await thinking_msg.delete()

    if not success:
        await message.answer(
            "AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.\n\n"
            "–í–∞—à –æ—Ç–≤–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–æ–∑–∂–µ.",
            reply_markup=get_main_menu_keyboard(),
        )
        await state.set_state(None)
        return

    # Increment question count
    question_count += 1

    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥—Å–∫–∞–∑–∫—É –ø–æ—Å–ª–µ 7 –≤–æ–ø—Ä–æ—Å–æ–≤
    MAX_QUESTIONS_BEFORE_HINT = 7
    if question_count >= MAX_QUESTIONS_BEFORE_HINT and question_count % 3 == 1:
        ai_question += "\n\n_–ü–æ–¥—Å–∫–∞–∑–∫–∞: —É –≤–∞—Å —É–∂–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞! –ù–∞–∂–º–∏—Ç–µ ¬´–°–æ–∑–¥–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é¬ª —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–∞—Å—Å–∫–∞–∑–∞–Ω–Ω–æ–µ._"

    messages.append({"role": "assistant", "content": ai_question})

    # Update state
    await state.update_data(
        interview_messages=messages,
        question_count=question_count,
    )

    # Update interaction time
    user_storage.update_user_interaction(message.from_user.id)

    # Build response with progress
    progress = get_progress_text(question_count)
    response_text = f"{ai_question}\n\n{progress}"

    # Send next question
    await message.answer(
        response_text,
        reply_markup=get_interview_keyboard(question_count, MIN_QUESTIONS_FOR_STORY),
    )


async def create_story_from_messages(message: Message, state: FSMContext):
    """Create story from current interview messages."""
    data = await state.get_data()
    messages = data.get("interview_messages", [])
    relative_id = data["relative_id"]

    if len(messages) < 2:
        await message.answer(
            "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏.",
            reply_markup=get_interview_keyboard(data.get("question_count", 0), MIN_QUESTIONS_FOR_STORY),
        )
        return

    await message.answer("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∞—à–∏ –æ—Ç–≤–µ—Ç—ã...")

    story_result = await ai_service.create_story(messages)

    if not story_result:
        await message.answer(
            "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –µ—â—ë –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å–æ–≤.",
            reply_markup=get_interview_keyboard(data.get("question_count", 0), MIN_QUESTIONS_FOR_STORY),
        )
        return

    title, content, has_content = story_result

    if not has_content:
        # AI determined there's not enough content
        await message.answer(
            f"*–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏*\n\n"
            f"_{content}_\n\n"
            f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ - —Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å–æ–±—ã—Ç–∏—è—Ö, –ª—é–¥—è—Ö, –º–µ—Å—Ç–∞—Ö.",
            parse_mode="Markdown",
            reply_markup=get_interview_keyboard(data.get("question_count", 0), MIN_QUESTIONS_FOR_STORY),
        )
        return

    # Store pending story for confirmation
    await state.update_data(
        pending_story_title=title,
        pending_story_text=content,
    )
    await state.set_state(InterviewStates.confirming_story)

    # Show preview (up to 1500 chars)
    preview_length = min(len(content), 1500)
    story_preview = content[:preview_length]
    if len(content) > preview_length:
        story_preview += "..."

    # Escape markdown
    story_preview = story_preview.replace("_", "\\_").replace("*", "\\*")
    escaped_title = title.replace("_", "\\_").replace("*", "\\*")

    await message.answer(
        f"*{escaped_title}*\n\n"
        f"{story_preview}\n\n"
        f"---\n"
        f"–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç—Ç—É –∏—Å—Ç–æ—Ä–∏—é?",
        parse_mode="Markdown",
        reply_markup=get_story_confirmation_keyboard(),
    )


@router.callback_query(InterviewStates.confirming_story, F.data == "story_save")
async def confirm_story_save(callback: CallbackQuery, state: FSMContext):
    """Save the confirmed story and offer to add photos."""
    data = await state.get_data()
    relative_id = data["relative_id"]
    title = data.get("pending_story_title", "–ò—Å—Ç–æ—Ä–∏—è")
    text = data.get("pending_story_text", "")

    # Save to backend
    success = await backend_api.save_story(relative_id, title, text)

    await callback.answer()

    if success:
        # Save story key for photo uploads
        await state.update_data(
            saved_story_key=title,
            story_photo_count=0,
        )
        await state.set_state(InterviewStates.collecting_story_photos)

        await callback.message.edit_text(
            f"*{title}*\n\n"
            f"–ò—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!\n\n"
            f"üì∏ –•–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –∫ —ç—Ç–æ–π –∏—Å—Ç–æ—Ä–∏–∏? (–¥–æ 5 —à—Ç—É–∫)\n"
            f"–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å¬ª",
            parse_mode="Markdown",
        )

        await callback.message.answer(
            "–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
            reply_markup=get_photo_collection_keyboard(),
        )
    else:
        await callback.message.edit_text(
            "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.",
        )
        await state.set_state(InterviewStates.waiting_answer)


@router.callback_query(InterviewStates.confirming_story, F.data == "story_discard")
async def confirm_story_discard(callback: CallbackQuery, state: FSMContext):
    """Discard the story and continue."""
    await callback.answer("–ò—Å—Ç–æ—Ä–∏—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–∞")

    # Clear pending story
    await state.update_data(
        pending_story_title=None,
        pending_story_text=None,
    )
    await state.set_state(InterviewStates.waiting_answer)

    data = await state.get_data()
    question_count = data.get("question_count", 0)

    await callback.message.edit_text(
        "–ò—Å—Ç–æ—Ä–∏—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–∞. –ü—Ä–æ–¥–æ–ª–∂–∏–º –∏–Ω—Ç–µ—Ä–≤—å—é - –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ç–≤–µ—Ç–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ.",
    )

    await callback.message.answer(
        "–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º?",
        reply_markup=get_interview_keyboard(question_count, MIN_QUESTIONS_FOR_STORY),
    )


@router.callback_query(InterviewStates.confirming_story, F.data == "story_continue")
async def confirm_story_continue(callback: CallbackQuery, state: FSMContext):
    """Continue interview without saving story."""
    await callback.answer()

    # Clear pending story but keep messages
    await state.update_data(
        pending_story_title=None,
        pending_story_text=None,
    )
    await state.set_state(InterviewStates.waiting_answer)

    data = await state.get_data()
    question_count = data.get("question_count", 0)
    messages = data.get("interview_messages", [])
    relative_id = data["relative_id"]
    relative_name = data.get("relative_name", "")

    await callback.message.edit_text(
        "–•–æ—Ä–æ—à–æ, –ø—Ä–æ–¥–æ–ª–∂–∏–º –∏–Ω—Ç–µ—Ä–≤—å—é - –¥–æ–±–∞–≤–∏–º –±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π.",
    )

    # Get next question
    thinking_msg = await callback.message.answer("...")

    covered_topics = extract_topics_from_messages(messages)
    related_stories_context = await backend_api.get_related_stories(relative_id)

    ai_question, success = await ai_service.get_interview_question(
        messages, relative_name, covered_topics, related_stories_context
    )

    await thinking_msg.delete()

    if success:
        question_count += 1
        messages.append({"role": "assistant", "content": ai_question})
        await state.update_data(
            interview_messages=messages,
            question_count=question_count,
        )

        progress = get_progress_text(question_count)
        await callback.message.answer(
            f"{ai_question}\n\n{progress}",
            reply_markup=get_interview_keyboard(question_count, MIN_QUESTIONS_FOR_STORY),
        )
    else:
        await callback.message.answer(
            "AI –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=get_main_menu_keyboard(),
        )


# ============ Relative Info Collection Handlers ============


@router.message(InterviewStates.collecting_relative_info, F.text)
async def handle_relative_info(message: Message, state: FSMContext):
    """Handle answers about the mentioned relative."""
    data = await state.get_data()
    mentioned = data.get("mentioned_relative", {})
    collected = data.get("relative_info_collected", {})
    questions_asked = data.get("relative_questions_asked", 0)

    # Check for skip command
    if message.text.lower() in ["–ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å", "skip", "–æ—Ç–º–µ–Ω–∞", "cancel"]:
        await return_to_interview(message, state)
        return

    # Extract info from the answer
    extracted = await ai_service.extract_relative_info_from_answer(
        answer=message.text,
        mentioned_name=mentioned.get("name", ""),
        question_asked=f"–í–æ–ø—Ä–æ—Å {questions_asked + 1}",
    )

    # Merge extracted info into collected
    for key, value in extracted.items():
        if value:
            collected[key] = value

    # Also store raw answer
    collected[f"answer_{questions_asked}"] = message.text
    questions_asked += 1

    if questions_asked >= 3:
        # Collected enough info - show role selection
        await state.update_data(
            relative_info_collected=collected,
            relative_questions_asked=questions_asked,
        )
        await state.set_state(InterviewStates.selecting_relative_role)

        name = mentioned.get("name", "—ç—Ç–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞")
        probable_role = mentioned.get("probable_role", "other")
        role_ru = RELATIONSHIP_TRANSLATIONS.get(probable_role, "—Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫")

        await message.answer(
            f"–û—Ç–ª–∏—á–Ω–æ! –°–æ–±—Ä–∞–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ {name}.\n\n"
            f"–ö–µ–º {name} —Ç–µ–±–µ –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è?\n"
            f"_(–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é: {role_ru})_",
            parse_mode="Markdown",
            reply_markup=get_relationship_keyboard(),
        )
    else:
        # Ask next question
        await state.update_data(
            relative_info_collected=collected,
            relative_questions_asked=questions_asked,
        )

        question = await ai_service.get_relative_info_question(
            mentioned_name=mentioned.get("name", ""),
            probable_role=mentioned.get("probable_role", "other"),
            context=mentioned.get("context", ""),
            already_collected=collected,
            question_number=questions_asked,
        )

        await message.answer(
            f"{question}\n\n"
            f"_({questions_asked + 1}/3 –≤–æ–ø—Ä–æ—Å–æ–≤. –ù–∞–ø–∏—à–∏ \"–ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å\" –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ –∏–Ω—Ç–µ—Ä–≤—å—é)_",
            parse_mode="Markdown",
        )


@router.callback_query(InterviewStates.selecting_relative_role, F.data.startswith("rel_"))
async def handle_relationship_selection(callback: CallbackQuery, state: FSMContext):
    """Handle relationship type selection."""
    role = callback.data.replace("rel_", "")

    if role == "skip":
        await callback.answer("–ü—Ä–æ–ø—É—â–µ–Ω–æ")
        await callback.message.delete()
        await return_to_interview(callback.message, state)
        return

    data = await state.get_data()
    mentioned = data.get("mentioned_relative", {})
    collected = data.get("relative_info_collected", {})
    relative_id = data.get("relative_id")

    # Prepare data for API
    name = mentioned.get("name", "")

    # –í–∞–ª–∏–¥–∞—Ü–∏—è: –∏–º—è –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–æ–ª—å—é
    ROLE_NAMES = {
        "–º–∞–º–∞", "–ø–∞–ø–∞", "–º–∞—Ç—å", "–æ—Ç–µ—Ü", "–±–∞–±—É—à–∫–∞", "–¥–µ–¥—É—à–∫–∞",
        "–±—Ä–∞—Ç", "—Å–µ—Å—Ç—Ä–∞", "–¥—è–¥—è", "—Ç—ë—Ç—è", "—Ç–µ—Ç—è", "—Å—ã–Ω", "–¥–æ—á—å",
        "–º—É–∂", "–∂–µ–Ω–∞", "—Å—É–ø—Ä—É–≥", "—Å—É–ø—Ä—É–≥–∞", "–¥–µ–¥", "–±–∞–±–∞",
        "mother", "father", "brother", "sister", "grandmother", "grandfather"
    }
    name_lower = name.lower().strip()
    if name_lower in ROLE_NAMES or not name.strip():
        await callback.answer("–ù—É–∂–Ω–æ —Ä–µ–∞–ª—å–Ω–æ–µ –∏–º—è")
        await callback.message.edit_text(
            "–î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ—Ñ–∏–ª—è –Ω—É–∂–Ω–æ –∑–Ω–∞—Ç—å –Ω–∞—Å—Ç–æ—è—â–µ–µ –∏–º—è —á–µ–ª–æ–≤–µ–∫–∞, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ —Ä–æ–ª—å.\n"
            "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –Ω—ë–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏–∏, –Ω–∞–∑–≤–∞–≤ –µ–≥–æ –∏–º—è."
        )
        await return_to_interview(callback.message, state)
        return

    await callback.answer("–°–æ–∑–¥–∞—é –ø—Ä–æ—Ñ–∏–ª—å...")
    # Try to get full name from collected info
    full_name = collected.get("full_name")
    if full_name:
        name_parts = full_name.split()
        first_name = name_parts[0] if name_parts else name
        last_name = " ".join(name_parts[1:]) if len(name_parts) > 1 else None
    else:
        first_name = name
        last_name = None

    birth_year = collected.get("birth_year")
    if birth_year and isinstance(birth_year, str):
        try:
            birth_year = int(birth_year)
        except ValueError:
            birth_year = None

    # Determine gender from role
    female_roles = {"mother", "grandmother", "sister", "aunt", "daughter", "niece"}
    male_roles = {"father", "grandfather", "brother", "uncle", "son", "nephew"}
    if role in female_roles:
        gender = "female"
    elif role in male_roles:
        gender = "male"
    else:
        gender = "other"

    # Format additional info
    additional_info = json.dumps(collected, ensure_ascii=False) if collected else None

    # Create relative via API
    try:
        result = await backend_api.create_relative_from_bot(
            interviewer_relative_id=relative_id,
            first_name=first_name,
            relationship_type=role,
            last_name=last_name,
            birth_year=birth_year,
            gender=gender,
            additional_info=additional_info,
        )

        if result:
            role_ru = RELATIONSHIP_TRANSLATIONS.get(role, "—Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫")
            await callback.message.edit_text(
                f"‚úÖ –ü—Ä–æ—Ñ–∏–ª—å —Å–æ–∑–¥–∞–Ω!\n\n"
                f"*{first_name}* ({role_ru})\n"
                f"–î–æ–±–∞–≤–ª–µ–Ω –≤ —Å–µ–º–µ–π–Ω–æ–µ –¥–µ—Ä–µ–≤–æ.",
                parse_mode="Markdown",
            )

            # Add to known relatives
            known_relatives = data.get("known_relatives", [])
            known_relatives.append(name)
            await state.update_data(known_relatives=known_relatives)

        else:
            await callback.message.edit_text(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Ñ–∏–ª—å. –ü—Ä–æ–¥–æ–ª–∂–∏–º –∏–Ω—Ç–µ—Ä–≤—å—é."
            )

    except Exception as e:
        logger.error(f"Error creating relative: {e}")
        await callback.message.edit_text(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–æ—Ñ–∏–ª—è. –ü—Ä–æ–¥–æ–ª–∂–∏–º –∏–Ω—Ç–µ—Ä–≤—å—é."
        )

    # Return to interview
    await return_to_interview(callback.message, state)


async def return_to_interview(message: Message, state: FSMContext):
    """Return to the main interview flow."""
    data = await state.get_data()

    # Clear relative collection data
    await state.update_data(
        mentioned_relative=None,
        relative_info_collected=None,
        relative_questions_asked=0,
        saved_answer_text=None,
    )
    await state.set_state(InterviewStates.waiting_answer)

    messages = data.get("interview_messages", [])
    question_count = data.get("question_count", 0)
    relative_id = data.get("relative_id")
    relative_name = data.get("relative_name", "")

    # Get next interview question
    thinking_msg = await message.answer("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏–Ω—Ç–µ—Ä–≤—å—é...")

    covered_topics = extract_topics_from_messages(messages)
    related_stories_context = await backend_api.get_related_stories(relative_id)

    ai_question, success = await ai_service.get_interview_question(
        messages, relative_name, covered_topics, related_stories_context
    )

    await thinking_msg.delete()

    if success:
        question_count += 1
        messages.append({"role": "assistant", "content": ai_question})
        await state.update_data(
            interview_messages=messages,
            question_count=question_count,
        )

        progress = get_progress_text(question_count)
        await message.answer(
            f"{ai_question}\n\n{progress}",
            reply_markup=get_interview_keyboard(question_count, MIN_QUESTIONS_FOR_STORY),
        )
    else:
        await message.answer(
            "AI –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            reply_markup=get_main_menu_keyboard(),
        )


# ============ Story Photo Collection Handlers ============

MAX_PHOTOS_PER_STORY = 5


@router.message(InterviewStates.collecting_story_photos, F.photo)
async def handle_story_photo(message: Message, state: FSMContext):
    """Handle photo upload for story."""
    data = await state.get_data()
    relative_id = data.get("relative_id")
    story_key = data.get("saved_story_key")
    photo_count = data.get("story_photo_count", 0)

    if not relative_id or not story_key:
        await message.answer(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ù–∞—á–Ω–∏—Ç–µ –∏–Ω—Ç–µ—Ä–≤—å—é –∑–∞–Ω–æ–≤–æ.",
            reply_markup=get_main_menu_keyboard(),
        )
        await state.clear()
        return

    if photo_count >= MAX_PHOTOS_PER_STORY:
        await message.answer(
            f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –≤ {MAX_PHOTOS_PER_STORY} —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π.\n"
            "–ù–∞–∂–º–∏—Ç–µ ¬´–ì–æ—Ç–æ–≤–æ¬ª –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è.",
        )
        return

    # Show loading indicator
    processing_msg = await message.answer("üì§ –ó–∞–≥—Ä—É–∂–∞—é —Ñ–æ—Ç–æ...")

    try:
        # Get the largest photo
        photo = message.photo[-1]
        file = await bot.get_file(photo.file_id)

        # Download file
        file_bytes = await bot.download_file(file.file_path)
        photo_data = file_bytes.read()

        # Upload to backend
        result = await backend_api.upload_story_media(
            relative_id,
            story_key,
            photo_data,
            f"photo_{photo_count + 1}.jpg",
        )

        await processing_msg.delete()

        if result:
            photo_count += 1
            await state.update_data(story_photo_count=photo_count)

            remaining = MAX_PHOTOS_PER_STORY - photo_count
            if remaining > 0:
                await message.answer(
                    f"‚úÖ –§–æ—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ ({photo_count}/{MAX_PHOTOS_PER_STORY})\n"
                    f"–ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –µ—â—ë {remaining}",
                    reply_markup=get_photo_collection_keyboard(photo_count),
                )
            else:
                await message.answer(
                    f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {MAX_PHOTOS_PER_STORY} —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π (–º–∞–∫—Å–∏–º—É–º).",
                )
                await finish_photo_collection(message, state)
        else:
            await message.answer(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–æ—Ç–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.",
            )
    except Exception as e:
        logger.error(f"Error uploading story photo: {e}")
        try:
            await processing_msg.delete()
        except Exception:
            pass
        await message.answer("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–æ—Ç–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")


@router.message(InterviewStates.collecting_story_photos, F.text == "‚úÖ –ì–æ—Ç–æ–≤–æ, —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é")
async def finish_photo_collection_done(message: Message, state: FSMContext):
    """Finish photo collection - done button."""
    await finish_photo_collection(message, state)


@router.message(InterviewStates.collecting_story_photos, F.text == "‚è≠ –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ñ–æ—Ç–æ")
async def finish_photo_collection_skip(message: Message, state: FSMContext):
    """Finish photo collection - skip button."""
    await finish_photo_collection(message, state)


async def finish_photo_collection(message: Message, state: FSMContext):
    """Finish photo collection and return to main menu."""
    data = await state.get_data()
    photo_count = data.get("story_photo_count", 0)
    story_key = data.get("saved_story_key", "–ò—Å—Ç–æ—Ä–∏—è")

    # Clear story photo data
    await state.update_data(
        saved_story_key=None,
        story_photo_count=0,
        pending_story_title=None,
        pending_story_text=None,
        interview_messages=[],
        question_count=0,
    )
    await state.set_state(None)

    if photo_count > 0:
        await message.answer(
            f"üìñ –ò—Å—Ç–æ—Ä–∏—è ¬´{story_key}¬ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Å {photo_count} —Ñ–æ—Ç–æ!\n\n"
            "–•–æ—Ç–∏—Ç–µ —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –µ—â—ë –æ–¥–Ω—É –∏—Å—Ç–æ—Ä–∏—é?",
            reply_markup=get_main_menu_keyboard(),
        )
    else:
        await message.answer(
            f"üìñ –ò—Å—Ç–æ—Ä–∏—è ¬´{story_key}¬ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!\n\n"
            "–•–æ—Ç–∏—Ç–µ —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –µ—â—ë –æ–¥–Ω—É –∏—Å—Ç–æ—Ä–∏—é?",
            reply_markup=get_main_menu_keyboard(),
        )
